{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "root = \"/Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "\n",
    "\n",
    "#go terms for orthology analysis from: Supplementary material/annotation_orthogroup_genes.xlsx\n",
    "go_terms = pd.read_excel(root + \"internal data/annotation_orthogroup_genes.xlsx\")\n",
    "\n",
    "#omics data sources\n",
    "omics_sources = pd.read_excel(root + \"internal data/external data sources.xlsx\")\n",
    "\n",
    "\n",
    "#floc_cor_genes /Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/Bence folder/Analysis of Clement-Ziza RNA-seq/filter_corr.csv\n",
    "floc_cor_genes = pd.read_csv(root + \"Bence folder/Analysis of Clement-Ziza RNA-seq/filter_corr.csv\")\n",
    "\n",
    "#structure_sequence_homology /Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/Bence folder/Structure_and_Sequence_comparisons/final_analysis.csv\n",
    "structure_sequence_homology = pd.read_csv(root + \"Bence folder/Structure_and_Sequence_comparisons/final_analysis.csv\")\n",
    "\n",
    "#srb11 DE genes /Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/Bence folder/Analysis of Clement-Ziza RNA-seq/DESeq2/DE_results.csv\n",
    "srb11_DE_genes = pd.read_csv(root + \"Bence folder/Analysis of Clement-Ziza RNA-seq/DESeq2/DE_results.csv\")\n",
    "\n",
    "\n",
    "#WI phenotypes /Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/Bence folder/Analysis of Jeffares phenotypes/growth_vs_adhesion.csv\n",
    "WI_phenotypes = pd.read_csv(root + \"Bence folder/Analysis of Jeffares phenotypes/growth_vs_adhesion.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#segregant genotypes/Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/internal data/updated_genotype_matrix_final_pos.tsv\n",
    "segregant_genotypes = pd.read_csv(root + \"internal data/updated_genotype_matrix_final_pos.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "#primers\n",
    "primers=pd.read_excel(root + \"internal data/Primers.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join all of these into a single xlsx file as different sheets. Also give a header to each sheet\n",
    "# which is \"# Title: \" + the name of the sheet\n",
    "# correspondance: bence.kover.19@ucl.ac.uk or j.bahler@ucl.ac.uk\n",
    "\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the output xlsx file\n",
    "output_file = root + \"Supplementary material/Supplementary table.xlsx\"\n",
    "\n",
    "# Create a Pandas Excel writer using the output file path\n",
    "writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "\n",
    "# Define a dictionary containing the dataframes and their corresponding sheet names\n",
    "dataframes = {\n",
    "    'go_terms': go_terms,\n",
    "    'omics_sources': omics_sources,\n",
    "    'floc_cor_genes': floc_cor_genes,\n",
    "    'structure_sequence_homology': structure_sequence_homology,\n",
    "    'srb11_DE_genes': srb11_DE_genes,\n",
    "    'WI_phenotypes': WI_phenotypes,\n",
    "    'segregant_genotypes': segregant_genotypes,\n",
    "    'primers': primers\n",
    "}\n",
    "\n",
    "# Loop through the dictionary and write each dataframe to a separate sheet in the output file\n",
    "for sheet_name, df in dataframes.items():\n",
    "    # Add a header to the sheet name\n",
    "    sheet_name = sheet_name\n",
    "    title = \"# Title: \" + sheet_name\n",
    "    correspondance = \"# Correspondance: bence.kover.19@ucl.ac.uk or j.bahler@ucl.ac.uk\"\n",
    "    \n",
    "    # Write the dataframe to the sheet\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=2)\n",
    "    \n",
    "    # Get the xlsxwriter workbook and worksheet objects\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    \n",
    "    # Add the title and correspondance to the sheet\n",
    "    worksheet.write(0, 0, title)\n",
    "    worksheet.write(1, 0, correspondance)\n",
    "    \n",
    "    # Move the column names down\n",
    "    for i, col in enumerate(df.columns):\n",
    "        worksheet.write(2, i, col)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now assemble .pdf of all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/bencekover/opt/anaconda3/lib/python3.9/site-packages (9.4.0)\n",
      "Requirement already satisfied: fpdf2 in /Users/bencekover/opt/anaconda3/lib/python3.9/site-packages (2.7.5)\n",
      "Requirement already satisfied: defusedxml in /Users/bencekover/opt/anaconda3/lib/python3.9/site-packages (from fpdf2) (0.7.1)\n",
      "Requirement already satisfied: fonttools>=4.34.0 in /Users/bencekover/opt/anaconda3/lib/python3.9/site-packages (from fpdf2) (4.42.1)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /Users/bencekover/opt/anaconda3/lib/python3.9/site-packages (from PyPDF2) (4.6.3)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow fpdf2\n",
    "!pip install PyPDF2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mb/vdj4y7t13zd3tzlk99b8ycd40000gn/T/ipykernel_30950/2836831980.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img.thumbnail((new_width, new_height), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None \n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Image as ReportLabImage, Paragraph, PageBreak\n",
    "from reportlab.lib.styles import ParagraphStyle\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Image as ReportLabImage\n",
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "def compress_pdf(pdf_path):\n",
    "    compressed_path = pdf_path.replace(\".pdf\", \"_compressed.pdf\")\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "\n",
    "        for page in pdf_reader.pages:\n",
    "            pdf_writer.add_page(page)\n",
    "\n",
    "        with open(compressed_path, \"wb\") as compressed_pdf:\n",
    "            pdf_writer.write(compressed_pdf)\n",
    "\n",
    "    os.remove(pdf_path)  # Remove the original uncompressed PDF\n",
    "    os.rename(compressed_path, pdf_path)  # Rename the compressed PDF to original name\n",
    "\n",
    "\n",
    "\n",
    "def create_pdf_from_images(image_paths, output_path, n_main_figs, n_supp_figs):\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=A4)\n",
    "    story = []\n",
    "\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        aspect_ratio = height / float(width)\n",
    "        new_width = 500  # You can adjust this width as needed for A4 layout\n",
    "        new_height = new_width * aspect_ratio\n",
    "        if new_height > 600:\n",
    "            new_height = 600\n",
    "            new_width = new_height / aspect_ratio\n",
    "        img.thumbnail((new_width, new_height), Image.ANTIALIAS)\n",
    "\n",
    "        reportlab_img = ReportLabImage(image_path, width=new_width, height=new_height)\n",
    "        \n",
    "        \n",
    "        # Add a caption to the PDF document\n",
    "        if i < n_main_figs:\n",
    "            caption = f\"<strong>Figure {i+1}</strong>\"\n",
    "        elif i < n_main_figs + n_supp_figs:\n",
    "            caption = f\"<strong>Supplementary Figure {i-n_main_figs+1}</strong>\"\n",
    "        else:\n",
    "            caption = \"\"\n",
    "        caption_style = ParagraphStyle(name='Caption', fontSize=16, leading=14)\n",
    "        story.append(Paragraph(caption, caption_style))\n",
    "        #paragraph\n",
    "        story.append(Paragraph(\"<br/>\", caption_style))\n",
    "        story.append(Paragraph(\"<br/>\", caption_style))\n",
    "        story.append(Paragraph(\"<br/>\", caption_style))\n",
    "        story.append(reportlab_img)\n",
    "        story.append(PageBreak())\n",
    "\n",
    "\n",
    "    doc.build(story)\n",
    "    compress_pdf(output_path)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "image_paths = [\n",
    "    root + \"Figures/Figure 0/figure0.png\",\n",
    "    root + \"Figures/Figure 1/figure 1.png\",\n",
    "    root + \"Figures/Figure 2/fig2.png\",\n",
    "    root + \"Figures/Figure 3/figure3.png\",\n",
    "    root + \"Figures/Figure 4/figure4.png\",\n",
    "    root + \"Figures/Figure 5/final_final plot.png\",\n",
    "    root + \"Figures/Supplementary figure 1./supfig1.png\",\n",
    "    root + \"Figures/Supplementary figure 2./supp_fig2.png\",\n",
    "    root + \"Figures/Supplementary figure 3./supp_fig3.png\",\n",
    "    root + \"Figures/Supplementary figure 4./suppfig4.png\",\n",
    "    root + \"Figures/Supplementary figure 5./supp_fig5.png\",\n",
    "    root + \"Figures/Supplementary figure 6./supp_fig6.png\",\n",
    "    root + \"Figures/Supplementary figure 7./supp_fig7.png\",\n",
    "    root + \"Figures/Supplementary figure 8./supfig8.png\",\n",
    "    root + \"Figures/Supplementary figure 9./supfig9.png\",\n",
    "    root + \"Figures/Supplementary figure 10./supp_fig10.png\",\n",
    "    root + \"Figures/Supplementary figure 11./supp_fig11.png\",\n",
    "    root + \"Figures/Supplementary figure 12./supp_fig12.png\",\n",
    "    root + \"Figures/Supplementary figure 13./supfig13.png\",\n",
    "\n",
    "]\n",
    "output_path = root + \"Supplementary material/figures.pdf\"\n",
    "\n",
    "create_pdf_from_images(image_paths, output_path,6,13)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d0398177d7bb10ea33b6a5cd9d022d63e20680fcfd84762562c72ff35bdf44b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
