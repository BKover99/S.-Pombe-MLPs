{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests import get\n",
    "root = \"/Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/\"\n",
    "\n",
    "\n",
    "def get_amino_acid_sequence(uniprot_id):\n",
    "    base_url = \"https://www.uniprot.org/uniprot/\"\n",
    "    response_format = \".fasta\"\n",
    "\n",
    "    # Combine the URL to get the FASTA format data for the given UniProt ID\n",
    "    url = f\"{base_url}{uniprot_id}{response_format}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes (e.g., 404, 500)\n",
    "\n",
    "        # Parse the response to extract the amino acid sequence\n",
    "        lines = response.text.strip().split(\"\\n\")\n",
    "        sequence = \"\".join(lines[1:])  # Skipping the first line (header)\n",
    "\n",
    "        return sequence\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred while fetching the data: {e}\")\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_top_e_val(uniprot_id, max_retries=10):\n",
    "    \"\"\"\n",
    "    Performs a BLAST search against the NCBI nr database for the given UniProt ID.\n",
    "    Returns the top hit's e-value and score.\n",
    "\n",
    "    :param uniprot_id: The UniProt ID to search for.\n",
    "    :param max_retries: The maximum number of times to retry the BLAST search if it fails.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    query_sequence = get_amino_acid_sequence(uniprot_id)\n",
    "    hits = []\n",
    "\n",
    "    #values to return\n",
    "    cerevisiae_e_val = np.nan\n",
    "    cerevisiae_score = np.nan\n",
    "    cerevisiae_symbol = \"N/A\"\n",
    "    albicans_e_val = np.nan\n",
    "    albicans_score = np.nan\n",
    "    albicans_symbol = \"N/A\"\n",
    "\n",
    "    for retry in range(max_retries + 1):\n",
    "        try:\n",
    "            # Perform the BLAST search\n",
    "            print(\"BLAST starts\")\n",
    "\n",
    "\n",
    "\n",
    "            result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", query_sequence, expect=1000, entrez_query=\"txid237561[ORGN] OR txid5476[ORGN] OR txid559292[ORGN] OR txid4932[ORGN]\",hitlist_size=1000)\n",
    "\n",
    "            blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "            hits = []\n",
    "            for blast_record in blast_records:\n",
    "                for alignment in blast_record.alignments:\n",
    "                    for hsp in alignment.hsps:\n",
    "                        hit_info = {\n",
    "                                        \"accession\": alignment.accession,\n",
    "                                        \"description\": alignment.title,\n",
    "                                        \"evalue\": hsp.expect,\n",
    "                                        \"score\": hsp.score\n",
    "                                    }\n",
    "                        hits.append(hit_info)\n",
    "            #in hits find entries, where description contains the string \"Saccharomyces cerevisiae\"\n",
    "            cerevisiae_entries = [hit for hit in hits if \"Saccharomyces cerevisiae\" in hit[\"description\"]]\n",
    "            albicans_entries = [hit for hit in hits if \"Candida albicans\" in hit[\"description\"]]\n",
    "            #order these by hgihest score first lowest score last\n",
    "            cerevisiae_entries = sorted(cerevisiae_entries, key=lambda x: x[\"score\"], reverse=True)\n",
    "            albicans_entries = sorted(albicans_entries, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "            if len(cerevisiae_entries) > 0:\n",
    "                cerevisiae_e_val = cerevisiae_entries[0][\"evalue\"]\n",
    "                cerevisiae_score = cerevisiae_entries[0][\"score\"]\n",
    "                cerevisiae_symbol = cerevisiae_entries[0][\"accession\"]\n",
    "            \n",
    "            \n",
    "            if len(albicans_entries) > 0:\n",
    "                albicans_e_val = albicans_entries[0][\"evalue\"]\n",
    "                albicans_score = albicans_entries[0][\"score\"]\n",
    "                albicans_symbol = albicans_entries[0][\"accession\"]\n",
    "\n",
    "            return cerevisiae_e_val, cerevisiae_score, cerevisiae_symbol, albicans_e_val, albicans_score, albicans_symbol\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during attempt {retry + 1}: {e}\")\n",
    "            if retry < max_retries:\n",
    "                print(\"Retrying...\")\n",
    "                time.sleep(60)  # Add a delay before retrying\n",
    "            else:\n",
    "                print(f\"Max retries reached, returning default values.\")\n",
    "                return cerevisiae_e_val, cerevisiae_score, cerevisiae_symbol, albicans_e_val, albicans_score, albicans_symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pombase gene products file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "root = \"/Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci Bahler lab/S.-Pombe-MLPs - Github/\"\n",
    "gene_info = pd.read_csv(root + \"external data/Pombase files/gene_IDs_names_products.tsv\", sep='\\t', header=0)\n",
    "gene_info = gene_info[[\"SPAC1002.01\", \"Q9US57\", \"mrx11\"]]\n",
    "gene_info = gene_info.rename(columns={\"SPAC1002.01\": \"ID\", \"Q9US57\": \"uniprot\", \"mrx11\":\"gene_name\"})\n",
    "\n",
    "orthology_db = pd.read_csv(root + \"Bence folder/Orthologs/final_orthology_database.csv\")\n",
    "#fetch the list of pombe_gene_IDs with orthopattern 7 and 1 into lists called conserved, unique\n",
    "unique_genes= orthology_db[orthology_db['orthopattern'] == 1][\"pombe_name(s)\"].values\n",
    "unique_genes = np.array([element[2:-2] for element in unique_genes])\n",
    "unique_genes_uniprot = np.array([])\n",
    "to_be_deleted = np.array([],dtype=int)\n",
    "for i in range(len(unique_genes)):\n",
    "    #find in gene_info the uniprot ID of the gene\n",
    "    try:\n",
    "        unique_genes_uniprot = np.append(unique_genes_uniprot, gene_info[gene_info[\"ID\"] == unique_genes[i]][\"uniprot\"].values[0])\n",
    "    except:\n",
    "        unique_genes_uniprot = unique_genes_uniprot\n",
    "        #remove that entry from unique_genes\n",
    "        to_be_deleted = np.append(to_be_deleted, i)\n",
    "unique_genes = np.delete(unique_genes, to_be_deleted)\n",
    "\n",
    "\n",
    "\n",
    "conserved_genes= orthology_db[orthology_db['orthopattern'] == 7][\"pombe_name(s)\"].values\n",
    "conserved_genes = np.array([element[2:-2] for element in conserved_genes])\n",
    "#take uniprot IDs but in the same order!\n",
    "conserved_genes_uniprot = np.array([])\n",
    "to_be_deleted = np.array([],dtype=int)\n",
    "for i in range(len(conserved_genes)):\n",
    "    try:\n",
    "        conserved_genes_uniprot = np.append(conserved_genes_uniprot, gene_info[gene_info[\"ID\"] == conserved_genes[i]][\"uniprot\"].values[0])\n",
    "    except:\n",
    "        conserved_genes_uniprot = conserved_genes_uniprot\n",
    "        to_be_deleted = np.append(to_be_deleted, i)\n",
    "conserved_genes = np.delete(conserved_genes, to_be_deleted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conserved_e_vals_cerevisiae = np.full(50, np.nan)\n",
    "conserved_scores_cerevisiae = np.full(50, np.nan)\n",
    "conserved_e_vals_albicans = np.full(50, np.nan)\n",
    "conserved_scores_albicans = np.full(50, np.nan)\n",
    "conserved_symbols_cerevisiae = np.full(50, \"N/A\")\n",
    "conserved_symbols_albicans = np.full(50, \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file loaded, entries: 49\n",
      "file loaded, entries: 49\n",
      "file loaded, entries: 49\n",
      "file loaded, entries: 49\n",
      "BLAST starts\n",
      "2.49563e-69 600.0 CAI5238588 4.4486e-63 551.0 KGU29933 SPAC22H10.07 P40996\n",
      "currently at entry 49 of 1070\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    conserved_e_vals_cerevisiae = np.loadtxt('conserved_e_vals_cerevisiae_final.txt')\n",
    "    #drop all values after the last non nan value\n",
    "    n_entries = np.where(~np.isnan(conserved_e_vals_cerevisiae))[0][-1]\n",
    "    \n",
    "    conserved_e_vals_cerevisiae = conserved_e_vals_cerevisiae[:n_entries]\n",
    "    #fill the rest with nan\n",
    "    conserved_e_vals_cerevisiae = np.append(conserved_e_vals_cerevisiae, np.full(50-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "\n",
    "except:\n",
    "    conserved_e_vals_cerevisiae = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    conserved_scores_cerevisiae = np.loadtxt('conserved_scores_cerevisiae_final.txt')\n",
    "    conserved_scores_cerevisiae = conserved_scores_cerevisiae[:n_entries]\n",
    "    conserved_scores_cerevisiae = np.append(conserved_scores_cerevisiae, np.full(50-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\",n_entries)\n",
    "except:\n",
    "    conserved_scores_cerevisiae = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    conserved_e_vals_albicans = np.loadtxt('conserved_e_vals_albicans_final.txt')\n",
    "    conserved_e_vals_albicans = conserved_e_vals_albicans[:n_entries]\n",
    "    conserved_e_vals_albicans = np.append(conserved_e_vals_albicans, np.full(50-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "except:\n",
    "    conserved_e_vals_albicans = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    conserved_scores_albicans = np.loadtxt('conserved_scores_albicans_final.txt')\n",
    "    conserved_scores_albicans = conserved_scores_albicans[:n_entries]\n",
    "    conserved_scores_albicans = np.append(conserved_scores_albicans, np.full(50-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "\n",
    "except:\n",
    "    conserved_scores_albicans = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    conserved_symbols_cerevisiae = np.loadtxt('conserved_symbols_cerevisiae_final.txt', dtype=str)\n",
    "    conserved_symbols_cerevisiae = conserved_symbols_cerevisiae[:n_entries]\n",
    "    conserved_symbols_cerevisiae = np.append(conserved_symbols_cerevisiae, np.full(50-n_entries, \"N/A\"))\n",
    "    print(\"file loaded, entries:\", len(n_entries))\n",
    "\n",
    "except:\n",
    "    conserved_symbols_cerevisiae = np.full(50, \"N/A\")\n",
    "\n",
    "try:\n",
    "    conserved_symbols_albicans = np.loadtxt('conserved_symbols_albicans_final.txt', dtype=str)\n",
    "    conserved_symbols_albicans = conserved_symbols_albicans[:n_entries]\n",
    "    conserved_symbols_albicans = np.append(conserved_symbols_albicans, np.full(50-n_entries, \"N/A\"))\n",
    "    print(\"file loaded, entries:\", len(n_entries))\n",
    "\n",
    "except:\n",
    "    conserved_symbols_albicans = np.full(50, \"N/A\")\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n_entries,50):\n",
    "\n",
    "    cerevisiae_e_val, cerevisiae_score, cerevisiae_symbol, albicans_e_val, albicans_score, albicans_symbol = get_top_e_val(conserved_genes_uniprot[i]) \n",
    "    print(cerevisiae_e_val, cerevisiae_score, cerevisiae_symbol, albicans_e_val, albicans_score, albicans_symbol,conserved_genes[i],conserved_genes_uniprot[i])\n",
    "    print(\"currently at entry\", i, \"of\", len(conserved_genes_uniprot))\n",
    "    conserved_e_vals_cerevisiae[i] = cerevisiae_e_val\n",
    "    conserved_scores_cerevisiae[i] = cerevisiae_score\n",
    "    conserved_symbols_cerevisiae[i] = cerevisiae_symbol\n",
    "    conserved_e_vals_albicans[i] = albicans_e_val\n",
    "    conserved_scores_albicans[i] = albicans_score\n",
    "    conserved_symbols_albicans[i] = albicans_symbol\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt('conserved_e_vals_cerevisiae_final.txt', conserved_e_vals_cerevisiae)\n",
    "np.savetxt('conserved_e_vals_albicans_final.txt', conserved_e_vals_albicans)\n",
    "np.savetxt('conserved_symbols_cerevisiae_final.txt', conserved_symbols_cerevisiae, fmt=\"%s\")\n",
    "np.savetxt('conserved_scores_cerevisiae_final.txt', conserved_scores_cerevisiae)\n",
    "np.savetxt('conserved_scores_albicans_final.txt', conserved_scores_albicans)\n",
    "np.savetxt('conserved_symbols_albicans_final.txt', conserved_symbols_albicans, fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('unique_e_vals_cerevisiae_final.txt', unique_e_vals_cerevisiae)\n",
    "np.savetxt('unique_e_vals_albicans_final.txt', unique_e_vals_albicans)\n",
    "np.savetxt('unique_scores_cerevisiae_final.txt', unique_scores_cerevisiae)\n",
    "np.savetxt('unique_scores_albicans_final.txt', unique_scores_albicans)\n",
    "np.savetxt('unique_symbols_cerevisiae_final.txt', unique_symbols_cerevisiae, fmt=\"%s\")\n",
    "np.savetxt('unique_symbols_albicans_final.txt', unique_symbols_albicans, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file loaded, entries: 24\n",
      "file loaded, entries: 24\n",
      "file loaded, entries: 24\n",
      "file loaded, entries: 24\n",
      "file loaded, entries: 24\n",
      "file loaded, entries: 24\n",
      "BLAST starts\n",
      "7.41212e-30 336.0 CAI7443233 3.17771e-33 364.0 KGT71740 SPCC895.05 O94532\n",
      "currently at entry 24 of 25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    unique_e_vals_cerevisiae = np.loadtxt('unique_e_vals_cerevisiae_final.txt')\n",
    "    #drop all values after the last non nan value\n",
    "    n_entries = np.where(~np.isnan(unique_e_vals_cerevisiae))[0][-1]\n",
    "    \n",
    "    unique_e_vals_cerevisiae = unique_e_vals_cerevisiae[:n_entries]\n",
    "    #fill up with nans\n",
    "    unique_e_vals_cerevisiae = np.append(unique_e_vals_cerevisiae, np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "\n",
    "except:\n",
    "    unique_e_vals_cerevisiae = np.array([])\n",
    "\n",
    "try:\n",
    "    unique_scores_cerevisiae = np.loadtxt('unique_scores_cerevisiae_final.txt')\n",
    "    unique_scores_cerevisiae = unique_scores_cerevisiae[:n_entries]\n",
    "    unique_scores_cerevisiae = np.append(unique_scores_cerevisiae, np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "except:\n",
    "    unique_scores_cerevisiae = np.array([])\n",
    "\n",
    "try:\n",
    "    unique_e_vals_albicans = np.loadtxt('unique_e_vals_albicans_final.txt')\n",
    "    unique_e_vals_albicans = unique_e_vals_albicans[:n_entries]\n",
    "    unique_e_vals_albicans = np.append(unique_e_vals_albicans, np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "except:\n",
    "    unique_e_vals_albicans = np.array([])\n",
    "\n",
    "try:\n",
    "    unique_scores_albicans = np.loadtxt('unique_scores_albicans_final.txt')\n",
    "    unique_scores_albicans = unique_scores_albicans[:n_entries]\n",
    "    unique_scores_albicans = np.append(unique_scores_albicans, np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "except:\n",
    "    unique_scores_albicans = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    unique_symbols_cerevisiae = np.loadtxt('unique_symbols_cerevisiae_final.txt', dtype=str)\n",
    "    unique_symbols_cerevisiae = unique_symbols_cerevisiae[:n_entries]\n",
    "    unique_symbols_cerevisiae = np.append(unique_symbols_cerevisiae, np.full(len(unique_genes_uniprot)-n_entries, \"N/A\"))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "\n",
    "except:\n",
    "    unique_symbols_cerevisiae = np.full(len(unique_genes_uniprot), \"N/A\")\n",
    "\n",
    "try:\n",
    "    unique_symbols_albicans = np.loadtxt('unique_symbols_albicans_final.txt', dtype=str)\n",
    "    unique_symbols_albicans = unique_symbols_albicans[:n_entries]\n",
    "    unique_symbols_albicans = np.append(unique_symbols_albicans, np.full(len(unique_genes_uniprot)-n_entries, \"N/A\"))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "\n",
    "except:\n",
    "    unique_symbols_albicans = np.full(len(unique_genes_uniprot), \"N/A\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n_entries,len(unique_genes_uniprot)):\n",
    "\n",
    "    cerevisiae_e_val, cerevisiae_score, cerevisiae_symbol, albicans_e_val, albicans_score, albicans_symbol = get_top_e_val(unique_genes_uniprot[i]) \n",
    "    print(cerevisiae_e_val, cerevisiae_score, cerevisiae_symbol, albicans_e_val, albicans_score, albicans_symbol,unique_genes[i],unique_genes_uniprot[i])\n",
    "    print(\"currently at entry\", i, \"of\", len(unique_genes_uniprot))\n",
    "    unique_e_vals_cerevisiae[i] = cerevisiae_e_val\n",
    "    unique_scores_cerevisiae[i] = cerevisiae_score\n",
    "    unique_symbols_cerevisiae[i] = cerevisiae_symbol\n",
    "    unique_e_vals_albicans[i] = albicans_e_val\n",
    "    unique_scores_albicans[i] = albicans_score\n",
    "    unique_symbols_albicans[i] = albicans_symbol\n",
    "\n",
    "\n",
    "#np.savetxt('unique_e_vals_cerevisiae_final.txt', unique_e_vals_cerevisiae)\n",
    "#np.savetxt('unique_e_vals_albicans_final.txt', unique_e_vals_albicans)\n",
    "#np.savetxt('unique_scores_cerevisiae_final.txt', unique_scores_cerevisiae)\n",
    "#np.savetxt('unique_scores_albicans_final.txt', unique_scores_albicans)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan, 2.33312e+02,         nan, 1.77122e+01, 4.86412e+02,\n",
       "               nan, 1.31248e-03, 1.56635e+02, 5.32609e-10, 2.50458e+02,\n",
       "       2.86622e-23, 4.86412e+02, 7.38255e-08, 4.78427e+02,         nan,\n",
       "       8.83257e-14, 7.45392e+00,         nan,         nan, 9.86924e-03,\n",
       "               nan, 2.44881e-04,         nan, 1.15489e+02, 7.41212e-30])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_e_vals_cerevisiae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('unique_e_vals_cerevisiae_final.txt', unique_e_vals_cerevisiae)\n",
    "np.savetxt('unique_e_vals_albicans_final.txt', unique_e_vals_albicans)\n",
    "np.savetxt('unique_scores_cerevisiae_final.txt', unique_scores_cerevisiae)\n",
    "np.savetxt('unique_scores_albicans_final.txt', unique_scores_albicans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def download_pdb_alphafold(uniprot_id, database_version='v2'):\n",
    "    \"\"\"\n",
    "    Downloads the AlphaFold protein structure and predicted error file for a given uniprot id\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uniprot_id : str\n",
    "        Uniprot id of the protein of interest\n",
    "    database_version : str, optional\n",
    "        Version of the AlphaFold database to use (default is 'v2')\n",
    "    \"\"\"\n",
    "    \n",
    "    alphafold_id = f'AF-{uniprot_id}-F1'\n",
    "    model_url = f'https://alphafold.ebi.ac.uk/files/{alphafold_id}-model_{database_version}.pdb'\n",
    "    error_url = f'https://alphafold.ebi.ac.uk/files/{alphafold_id}-predicted_aligned_error_{database_version}.json'\n",
    "\n",
    "    os.system(f'curl {model_url} -o {alphafold_id}.pdb')\n",
    "    os.system(f'curl {error_url} -o {alphafold_id}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "#import get\n",
    "from requests import get\n",
    "\n",
    "def scores_evals_from_uniprot(uniprot_id):\n",
    "    \"\"\"\n",
    "    Returns the e-value and score of the best hit in S. cerevisiae and C. albicans for a given uniprot id\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uniprot_id : str\n",
    "        Uniprot id of the protein of interest\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    download_pdb_alphafold(uniprot_id)\n",
    "    file = f'/Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci\\ Bahler\\ lab/S.-Pombe-MLPs\\ -\\ Github/Bence\\ folder/Structure_and_Sequence_comparisons/{uniprot_id}.pdb'\n",
    "    \n",
    "    x=0\n",
    "    \n",
    "    while x < 5:\n",
    "        try:\n",
    "            job = !curl -X POST -F q=@{file} -F 'mode=3diaa' -F 'database[]=afdb-swissprot' https://search.foldseek.com/api/ticket\n",
    "            job = job[-1].split('\"')[3]\n",
    "            result = get('https://search.foldseek.com/api/result/' + job + '/0').json()\n",
    "            x = 5\n",
    "        except:\n",
    "            time.sleep(60)\n",
    "            x += 1\n",
    "            print(\"waiting\")\n",
    "           \n",
    "    try:\n",
    "        taxids = [result[\"results\"][0][\"alignments\"][i][\"taxId\"] for i in range(len(result[\"results\"][0][\"alignments\"]))]\n",
    "        scores = [result[\"results\"][0][\"alignments\"][i][\"score\"] for i in range(len(result[\"results\"][0][\"alignments\"]))]\n",
    "        evals = [result[\"results\"][0][\"alignments\"][i][\"eval\"] for i in range(len(result[\"results\"][0][\"alignments\"]))]\n",
    "\n",
    "        #for top_score_cerevisiae find in taxids the entry which equals 4932 or 559292 and get the highest score and evalue from those\n",
    "        cerevisiae_index = [i for i, x in enumerate(taxids) if x == 4932 or x == 559292]\n",
    "        albicans_index = [i for i, x in enumerate(taxids) if x == 5476 or x== 237561]\n",
    "    except:\n",
    "        return 0,100,0,100\n",
    "    try:\n",
    "        top_cerevisiae_score = max([scores[i] for i in cerevisiae_index])\n",
    "        top_cerevisiae_eval = min([evals[i] for i in cerevisiae_index])\n",
    "    except:\n",
    "        print(\"no cerevisiae\")\n",
    "        top_cerevisiae_score = 0\n",
    "        top_cerevisiae_eval = 100\n",
    "        \n",
    "\n",
    "        #do the same for albicans\n",
    "        \n",
    "    try:\n",
    "        top_albicans_score = max([scores[i] for i in albicans_index])\n",
    "        top_albicans_eval = min([evals[i] for i in albicans_index])\n",
    "    except:\n",
    "        print(\"no albicans\")\n",
    "        top_albicans_score = 0\n",
    "        top_albicans_eval = 100\n",
    "        \n",
    "    #remove .pdb file\n",
    "    os.remove(f'/Users/bencekover/Library/CloudStorage/OneDrive-Personal/MSci\\ Bahler\\ lab/S.-Pombe-MLPs\\ -\\ Github/Bence\\ folder/Structure_and_Sequence_comparisons/{uniprot_id}.pdb')\n",
    "\n",
    "    return top_cerevisiae_score, top_cerevisiae_eval, top_albicans_score, top_albicans_eval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('unique_e_vals_cerevisiae_foldseek.txt', unique_e_vals_cerevisiae_foldseek)\n",
    "np.savetxt('unique_scores_cerevisiae_foldseek.txt', unique_scores_cerevisiae_foldseek)\n",
    "np.savetxt('unique_e_vals_albicans_foldseek.txt', unique_e_vals_albicans_foldseek)\n",
    "np.savetxt('unique_scores_albicans_foldseek.txt', unique_scores_albicans_foldseek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt('unique_e_vals_cerevisiae_foldseek.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  937k    0  937k    0     0   397k      0 --:--:--  0:00:02 --:--:--  397k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 27.2M    0 27.2M    0     0  3784k      0 --:--:--  0:00:07 --:--:-- 3784k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting\n",
      "waiting\n",
      "waiting\n",
      "waiting\n",
      "waiting\n",
      "0 100 0 100 SPCC895.05 O94532\n",
      "currently at entry 24 of 25 entries top\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    unique_e_vals_cerevisiae_foldseek = np.loadtxt('unique_e_vals_cerevisiae_foldseek_final.txt')\n",
    "    #drop all values after the last non nan value\n",
    "    n_entries = np.where(~np.isnan(unique_e_vals_cerevisiae_foldseek))[0][-1]\n",
    "    unique_e_vals_cerevisiae_foldseek = unique_e_vals_cerevisiae_foldseek[:n_entries]\n",
    "    #fill up the rest until len(unique_genes_uniprot) with nan\n",
    "    unique_e_vals_cerevisiae_foldseek = np.append(unique_e_vals_cerevisiae_foldseek, np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "\n",
    "except:\n",
    "    unique_e_vals_cerevisiae_foldseek = np.full(len(unique_genes_uniprot), np.nan)\n",
    "\n",
    "try:\n",
    "    unique_scores_cerevisiae_foldseek = np.loadtxt('unique_scores_cerevisiae_foldseek_final.txt')\n",
    "    unique_scores_cerevisiae_foldseek = unique_scores_cerevisiae_foldseek[:n_entries]\n",
    "    unique_scores_cerevisiae_foldseek = np.append(unique_scores_cerevisiae_foldseek, np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "except:\n",
    "    unique_scores_cerevisiae_foldseek = np.full(len(unique_genes_uniprot), np.nan)\n",
    "\n",
    "try:\n",
    "    unique_e_vals_albicans_foldseek = np.loadtxt('unique_e_vals_albicans_foldseek_final.txt')\n",
    "    unique_e_vals_albicans_foldseek = unique_e_vals_albicans_foldseek[:n_entries]\n",
    "    unique_e_vals_albicans_foldseek = np.append(unique_e_vals_albicans_foldseek, np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "except:\n",
    "    unique_e_vals_albicans_foldseek = np.full(len(unique_genes_uniprot), np.nan)\n",
    "\n",
    "try:\n",
    "    unique_scores_albicans_foldseek  = np.loadtxt('unique_scores_albicans_foldseek_final.txt')\n",
    "    unique_scores_albicans_foldseek  = unique_scores_albicans_foldseek [:n_entries]\n",
    "    unique_scores_albicans_foldseek  = np.append(unique_scores_albicans_foldseek , np.full(len(unique_genes_uniprot)-n_entries, np.nan))\n",
    "    print(\"file loaded, entries:\", n_entries)\n",
    "\n",
    "except:\n",
    "    unique_scores_albicans_foldseek = np.full(len(unique_genes_uniprot), np.nan)\n",
    "\n",
    "try:\n",
    "    for i in range(n_entries,len(unique_genes_uniprot)):\n",
    "        score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans = scores_evals_from_uniprot(unique_genes_uniprot[i])\n",
    "        print(score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans, unique_genes[i], unique_genes_uniprot[i])\n",
    "        print(\"currently at entry\", i, \"of\", len(unique_genes_uniprot), \"entries top\")\n",
    "        unique_e_vals_cerevisiae_foldseek[i] = eval_cerevisiae\n",
    "        unique_scores_cerevisiae_foldseek[i] = score_cerevisiae\n",
    "        unique_e_vals_albicans_foldseek[i] = eval_albicans\n",
    "        unique_scores_albicans_foldseek[i] = score_albicans\n",
    "\n",
    "except:\n",
    "    for i in range(len(unique_genes_uniprot)):\n",
    "        score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans = scores_evals_from_uniprot(unique_genes_uniprot[i])\n",
    "        print(score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans, unique_genes[i], unique_genes_uniprot[i])\n",
    "        print(\"currently at entry\", i, \"of\", len(unique_genes_uniprot), \"entries bot\")\n",
    "        unique_e_vals_cerevisiae_foldseek[i] = eval_cerevisiae\n",
    "        unique_scores_cerevisiae_foldseek[i] = score_cerevisiae\n",
    "        unique_e_vals_albicans_foldseek[i] = eval_albicans\n",
    "        unique_scores_albicans_foldseek[i] = score_albicans\n",
    "\n",
    "np.savetxt('unique_e_vals_cerevisiae_foldseek.txt', unique_e_vals_cerevisiae_foldseek)\n",
    "np.savetxt('unique_scores_cerevisiae_foldseek.txt', unique_scores_cerevisiae_foldseek)\n",
    "np.savetxt('unique_scores_albicans_foldseek.txt', unique_scores_albicans_foldseek)\n",
    "np.savetxt('unique_e_vals_albicans_foldseek.txt', unique_e_vals_albicans_foldseek)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  341k    0  341k    0     0  1231k      0 --:--:-- --:--:-- --:--:-- 1236k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3494k    0 3494k    0     0  3873k      0 --:--:-- --:--:-- --:--:-- 3870k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting\n",
      "waiting\n",
      "waiting\n",
      "waiting\n",
      "waiting\n",
      "0 100 0 100 SPAC22H10.07 P40996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    conserved_e_vals_cerevisiae_foldseek = np.loadtxt('conserved_e_vals_cerevisiae_final.txt')\n",
    "    #drop all values after the last non nan value\n",
    "    n_entries = np.where(~np.isnan(conserved_e_vals_cerevisiae_foldseek))[0][-1]\n",
    "    \n",
    "    conserved_e_vals_cerevisiae_foldseek = conserved_e_vals_cerevisiae_foldseek[:n_entries]\n",
    "    print(\"file loaded, entries:\", len(n_entries))\n",
    "\n",
    "except:\n",
    "    conserved_e_vals_cerevisiae_foldseek = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    conserved_scores_cerevisiae_foldseek = np.loadtxt('conserved_scores_cerevisiae_final.txt')\n",
    "    conserved_scores_cerevisiae_foldseek = conserved_scores_cerevisiae_foldseek[:n_entries]\n",
    "    print(\"file loaded, entries:\", len(n_entries))\n",
    "except:\n",
    "    conserved_scores_cerevisiae_foldseek = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    conserved_e_vals_albicans_foldseek = np.loadtxt('conserved_e_vals_albicans_final.txt')\n",
    "    conserved_e_vals_albicans_foldseek = conserved_e_vals_albicans_foldseek[:n_entries]\n",
    "    print(\"file loaded, entries:\", len(n_entries))\n",
    "except:\n",
    "    conserved_e_vals_albicans_foldseek = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    conserved_scores_albicans_foldseek  = np.loadtxt('conserved_scores_albicans_final.txt')\n",
    "    conserved_scores_albicans_foldseek  = conserved_scores_albicans_foldseek [:n_entries]\n",
    "    print(\"file loaded, entries:\", len(n_entries))\n",
    "\n",
    "except:\n",
    "    conserved_scores_albicans_foldseek = np.full(50, np.nan)\n",
    "\n",
    "try:\n",
    "    for i in range(n_entries,50):\n",
    "        score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans = scores_evals_from_uniprot(conserved_genes_uniprot[i])\n",
    "        print(score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans, conserved_genes[i], conserved_genes_uniprot[i])\n",
    "\n",
    "        conserved_e_vals_cerevisiae_foldseek[i] = eval_cerevisiae\n",
    "        conserved_scores_cerevisiae_foldseek[i] = score_cerevisiae\n",
    "        conserved_e_vals_albicans_foldseek[i] = eval_albicans\n",
    "        conserved_scores_albicans_foldseek[i] = score_albicans\n",
    "\n",
    "except:\n",
    "    for i in range(50):\n",
    "        score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans = scores_evals_from_uniprot(conserved_genes_uniprot[i])\n",
    "        print(score_cerevisiae, eval_cerevisiae, score_albicans, eval_albicans, conserved_genes[i], conserved_genes_uniprot[i])\n",
    "\n",
    "        conserved_e_vals_cerevisiae_foldseek[i] = eval_cerevisiae\n",
    "        conserved_scores_cerevisiae_foldseek[i] = score_cerevisiae\n",
    "        conserved_e_vals_albicans_foldseek[i] = eval_albicans\n",
    "        conserved_scores_albicans_foldseek[i] = score_albicans\n",
    "\n",
    "#np.savetxt('conserved_e_vals_cerevisiae_foldseek.txt', conserved_e_vals_cerevisiae_foldseek)\n",
    "#np.savetxt('conserved_scores_cerevisiae_foldseek.txt', conserved_scores_cerevisiae_foldseek)\n",
    "#np.savetxt('conserved_e_vals_albicans_foldseek.txt', conserved_e_vals_albicans_foldseek)\n",
    "#np.savetxt('conserved_scores_albicans_foldseek.txt', conserved_scores_albicans_foldseek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('conserved_e_vals_cerevisiae_foldseek.txt', conserved_e_vals_cerevisiae_foldseek)\n",
    "np.savetxt('conserved_scores_cerevisiae_foldseek.txt', conserved_scores_cerevisiae_foldseek)\n",
    "np.savetxt('conserved_e_vals_albicans_foldseek.txt', conserved_e_vals_albicans_foldseek)\n",
    "np.savetxt('conserved_scores_albicans_foldseek.txt', conserved_scores_albicans_foldseek)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uniprot_ids = np.concatenate((unique_genes_uniprot, conserved_genes_uniprot[:50], unique_genes_uniprot, conserved_genes_uniprot[:50], unique_genes_uniprot, conserved_genes_uniprot[:50], unique_genes_uniprot, conserved_genes_uniprot[:50]))\n",
    "all_gene_names = np.concatenate((unique_genes, conserved_genes[:50], unique_genes, conserved_genes[:50], unique_genes, conserved_genes[:50], unique_genes, conserved_genes[:50]))\n",
    "all_scores = np.concatenate((unique_scores_cerevisiae, conserved_scores_cerevisiae[:50], unique_scores_cerevisiae_foldseek, conserved_scores_cerevisiae_foldseek[:50], unique_scores_albicans, conserved_scores_albicans[:50], unique_scores_albicans_foldseek, conserved_scores_albicans_foldseek[:50]))\n",
    "all_e_vals = np.concatenate((unique_e_vals_cerevisiae, conserved_e_vals_cerevisiae[:50], unique_e_vals_cerevisiae_foldseek, conserved_e_vals_cerevisiae_foldseek[:50], unique_e_vals_albicans, conserved_e_vals_albicans[:50], unique_e_vals_albicans_foldseek, conserved_e_vals_albicans_foldseek[:50]))\n",
    "unique_conserved = np.concatenate((np.full(len(unique_genes), 'unique'), np.full(50, 'conserved'), np.full(len(unique_genes), 'unique'), np.full(50, 'conserved'), np.full(len(unique_genes), 'unique'), np.full(50, 'conserved'), np.full(len(unique_genes), 'unique'), np.full(50, 'conserved')))\n",
    "data_sources = np.concatenate((np.full(len(unique_genes), 'BlastP'), np.full(50, 'BlastP'), np.full(len(unique_genes), 'Foldseek'), np.full(50, 'Foldseek'), np.full(len(unique_genes), 'BlastP'), np.full(50, 'BlastP'), np.full(len(unique_genes), 'Foldseek'), np.full(50, 'Foldseek')))\n",
    "#species S. cerevisiae or C. albicans\n",
    "species = np.concatenate((np.full(len(unique_genes), 'S. cerevisiae'), np.full(50, 'S. cerevisiae'), np.full(len(unique_genes), 'S. cerevisiae'), np.full(50, 'S. cerevisiae'), np.full(len(unique_genes), 'C. albicans'), np.full(50, 'C. albicans'), np.full(len(unique_genes), 'C. albicans'), np.full(50, 'C. albicans')))\n",
    "#create a df with uniprot IDs, gene names, scores and e-values, data_source, unique/conserved, species\n",
    "df = pd.DataFrame({'uniprot_id': all_uniprot_ids, 'gene_name': all_gene_names, 'score': all_scores, 'e_value': all_e_vals, 'unique_conserved': unique_conserved, 'data_source': data_sources, 'species': species})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pombe_floc_dict = {\"SPAC186.01\":\"pfl9\",\n",
    "                   \"SPAC1F8.06\":\"pfl8\",\n",
    "                   \"SPBC359.04c\":\"pfl7\",\n",
    "                   \"SPAC977.07c\":\"pfl6\",\n",
    "                   \"SPBC1289.15\":\"pfl5\",\n",
    "                   \"SPCC188.09c\":\"pfl4\",\n",
    "                   \"SPBC947.04\":\"pfl3\",\n",
    "                   \"SPAP11E10.02c\":\"mam3\",\n",
    "                   \"SPAPB15E9.01c\":\"pfl2\",\n",
    "                   \"SPAPB2C8.01\":\"SPAPB2C8.01\",\n",
    "                   \"SPBC1348.08c\":\"SPBC1348.08c\",\n",
    "                   \"SPBC21D10.06c\":\"map4\",\n",
    "                   \"SPBPJ4664.02\":\"SPBPJ4664.02\",\n",
    "                   \"SPCC1742.01\":\"gsf2\"}\n",
    "\n",
    "df[\"color\"] = [\"True (n=14)\" if x in pombe_floc_dict.keys() else \"False\" for x in df[\"gene_name\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in df, for e_value turn Na into 100\n",
    "df['e_value'] = df['e_value'].fillna(100)\n",
    "#for score fill with 0\n",
    "df['score'] = df['score'].fillna(0)\n",
    "#any e_value higher than 100, turn into 100\n",
    "df['e_value'] = df['e_value'].apply(lambda x: 100 if x > 100 else x)\n",
    "#if lower than 10e-50, turn into 10e-50\n",
    "df['e_value'] = df['e_value'].apply(lambda x: 10e-150 if x < 10e-150 else x)\n",
    "#save df\n",
    "#df.to_csv(\"analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load df\n",
    "df = pd.read_csv(\"final_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 5.158e-07' [no close matches] {renderer: GlyphRenderer(id='p1988', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 7.274e-08' [no close matches] {renderer: GlyphRenderer(id='p1974', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 2.075e-02' [no close matches] {renderer: GlyphRenderer(id='p1995', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 1.825e-05' [no close matches] {renderer: GlyphRenderer(id='p1981', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 9.172e-03' [no close matches] {renderer: GlyphRenderer(id='p1967', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 5.477e-08' [no close matches] {renderer: GlyphRenderer(id='p1953', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 1.250e-05' [no close matches] {renderer: GlyphRenderer(id='p2002', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 9.466e-10' [no close matches] {renderer: GlyphRenderer(id='p1960', ...)}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mb/vdj4y7t13zd3tzlk99b8ycd40000gn/T/ipykernel_32181/2005307722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_svg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Figures/All figures/blast_p_foldseek_results.svg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Figures/All figures/blast_p_foldseek_results.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/export.py\u001b[0m in \u001b[0;36mexport_svg\u001b[0;34m(obj, filename, width, height, webdriver, timeout, state)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     '''\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0msvgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_svg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_write_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/export.py\u001b[0m in \u001b[0;36mget_svg\u001b[0;34m(obj, driver, timeout, resources, width, height, state)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mweb_driver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mwebdriver_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mweb_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"file://{tmp.path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mwait_until_render_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweb_driver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, kind)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDriverKind\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWebDriver\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drivers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bokeh/io/webdriver.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(self, kind)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             raise RuntimeError(\"Neither firefox and geckodriver nor a variant of chromium browser and \" \\\n\u001b[0m\u001b[1;32m    161\u001b[0m                                \u001b[0;34m\"chromedriver are available on system PATH. You can install the former \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                                \"with 'conda install -c conda-forge firefox geckodriver'.\")\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Neither firefox and geckodriver nor a variant of chromium browser and chromedriver are available on system PATH. You can install the former with 'conda install -c conda-forge firefox geckodriver'."
     ]
    }
   ],
   "source": [
    "import bokeh.io\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import Text\n",
    "from scipy import stats\n",
    "import iqplot\n",
    "import pandas as pd\n",
    "\n",
    "# Your DataFrame (df) and other data\n",
    "\n",
    "# Create the plot\n",
    "p = iqplot.stripbox(df, q=\"score\", cats=[\"data_source\", \"species\", \"unique_conserved\"], color_column=\"color\", q_axis=\"y\", frame_width=350, frame_height=300, spread=\"jitter\", jitter_kwargs={'width': 0.6},\n",
    "                    marker_kwargs=dict(size=8, alpha=0.5), box_kwargs=dict(line_color=\"black\", line_width=2), whisker_kwargs=dict(line_color=\"black\", line_width=2), median_kwargs=dict(line_color=\"black\", line_width=2), show_legend=True)\n",
    "\n",
    "# Customizations\n",
    "p.xaxis.major_label_orientation = 1.2\n",
    "p.xaxis.axis_label_text_font_size = '8pt'\n",
    "p.xaxis.major_label_text_font_size = '8pt'\n",
    "p.yaxis.axis_label_text_font_size = '8pt'\n",
    "p.xaxis.major_label_text_font_size = '8pt'\n",
    "p.yaxis.major_label_text_font_size = '8pt'\n",
    "p.xaxis.axis_label_text_font_style = 'normal'\n",
    "p.yaxis.axis_label_text_font_style = 'normal'\n",
    "p.yaxis.axis_label = 'Score'\n",
    "p.legend.title = 'Flocculin genes'\n",
    "\n",
    "# Calculate p-values\n",
    "p_vals = []\n",
    "p_vals_floc = []\n",
    "species_data_sources = [\n",
    "    ('C. albicans', 'BlastP'),\n",
    "    ('S. cerevisiae', 'BlastP'),\n",
    "    ('C. albicans', 'Foldseek'),\n",
    "    ('S. cerevisiae', 'Foldseek')\n",
    "\n",
    "]\n",
    "\n",
    "for species, data_source in species_data_sources:\n",
    "    unique_scores = df[(df['unique_conserved'] == 'unique') & (df['species'] == species) & (df['data_source'] == data_source)]['score']\n",
    "    unique_floc_scores = df[(df['unique_conserved'] == 'unique') & (df['species'] == species) & (df['data_source'] == data_source) & (df['color'] == \"True (n=14)\")]['score']\n",
    "    conserved_scores = df[(df['unique_conserved'] == 'conserved') & (df['species'] == species) & (df['data_source'] == data_source)]['score']\n",
    "    p_val = stats.mannwhitneyu(unique_scores, conserved_scores, alternative='two-sided')[1]\n",
    "    p_vals.append(p_val)\n",
    "    p_val_floc = stats.mannwhitneyu(unique_floc_scores, conserved_scores, alternative='two-sided')[1]\n",
    "    p_vals_floc.append(p_val_floc)\n",
    "\n",
    "# Create the text labels\n",
    "p_vals_labels = [\"p = {:.3e}\".format(p_val) for p_val in p_vals]\n",
    "p_vals_labels_floc = [\"p = {:.3e}\".format(p_val_floc) for p_val_floc in p_vals_floc]\n",
    "\n",
    "# Adjust text label positions\n",
    "x_positions = [1.3,4,7,9.7]  # Corresponding to the species and data_source combinations\n",
    "\n",
    "y_positions = [4100,4300,4100,4300]\n",
    "\n",
    "\n",
    "# Add text labels to the plot\n",
    "for x, y, label in zip(x_positions, y_positions, p_vals_labels):\n",
    "    text = Text(x=x, y=y+250, text=label, text_font_size='9.5pt', text_align='center', text_baseline='middle', text_color='black', text_alpha=1)\n",
    "    #place it above all elements\n",
    "    p.add_glyph(text, level='overlay')\n",
    "\n",
    "for x, y, label in zip(x_positions, y_positions, p_vals_labels_floc):\n",
    "    text = Text(x=x, y=y, text=label, text_font_size='9.5pt', text_align='center', text_baseline='middle', text_color='orange', text_alpha=1)\n",
    "    p.add_glyph(text, level='overlay')\n",
    "\n",
    "#ymax = 4800\n",
    "p.y_range = bokeh.models.Range1d(0, 4800)\n",
    "#make everything part of the same plot\n",
    "p.output_backend = \"svg\"\n",
    "p = bokeh.layouts.column(p)\n",
    "\n",
    "bokeh.io.export_svg(p, filename=root + \"Figures/All figures/blast_p_foldseek_results.svg\")\n",
    "bokeh.io.export_png(p, filename=root + \"Figures/All figures/blast_p_foldseek_results.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 5.158e-07' [no close matches] {renderer: GlyphRenderer(id='p1988', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 7.274e-08' [no close matches] {renderer: GlyphRenderer(id='p1974', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 2.075e-02' [no close matches] {renderer: GlyphRenderer(id='p1995', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 1.825e-05' [no close matches] {renderer: GlyphRenderer(id='p1981', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 9.172e-03' [no close matches] {renderer: GlyphRenderer(id='p1967', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 5.477e-08' [no close matches] {renderer: GlyphRenderer(id='p1953', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 1.250e-05' [no close matches] {renderer: GlyphRenderer(id='p2002', ...)}\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : text='p = 9.466e-10' [no close matches] {renderer: GlyphRenderer(id='p1960', ...)}\n"
     ]
    }
   ],
   "source": [
    "bokeh.io.show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-11-04T15:29:09.583002+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.0\n",
      "IPython version      : 7.31.1\n",
      "\n",
      "Compiler    : Clang 11.0.0 \n",
      "OS          : Darwin\n",
      "Release     : 21.5.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy     : 1.23.4\n",
      "pandas    : 1.4.4\n",
      "matplotlib: 3.8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d0398177d7bb10ea33b6a5cd9d022d63e20680fcfd84762562c72ff35bdf44b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
